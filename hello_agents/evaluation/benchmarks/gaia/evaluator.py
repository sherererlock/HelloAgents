"""
GAIA è¯„ä¼°å™¨æ¨¡å—

è´Ÿè´£è¯„ä¼°æ™ºèƒ½ä½“åœ¨ GAIA åŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°
"""

from typing import Dict, Any, List, Optional, Union
import time
import re
import json
from pathlib import Path
from hello_agents.evaluation.benchmarks.gaia.dataset import GAIADataset
from hello_agents.evaluation.benchmarks.gaia.metrics import GAIAMetrics


class GAIAEvaluator:
    """GAIA è¯„ä¼°å™¨

    è¯„ä¼°æ™ºèƒ½ä½“çš„é€šç”¨AIåŠ©æ‰‹èƒ½åŠ›,åŒ…æ‹¬:
    - é—®é¢˜ç†è§£å’Œæ¨ç†
    - å¤šæ­¥éª¤é—®é¢˜è§£å†³
    - å·¥å…·ä½¿ç”¨èƒ½åŠ›
    - ç­”æ¡ˆå‡†ç¡®æ€§

    GAIAè¯„ä¼°é‡‡ç”¨ä¸¥æ ¼çš„ç­”æ¡ˆåŒ¹é…æ ‡å‡†:
    - ç²¾ç¡®åŒ¹é…: ç­”æ¡ˆå®Œå…¨ä¸€è‡´
    - éƒ¨åˆ†åŒ¹é…: ç­”æ¡ˆåŒ…å«æ­£ç¡®ä¿¡æ¯ä½†æ ¼å¼ä¸åŒ

    Attributes:
        dataset: GAIA æ•°æ®é›†
        metrics: è¯„ä¼°æŒ‡æ ‡è®¡ç®—å™¨
        level: éš¾åº¦çº§åˆ«
        strict_mode: æ˜¯å¦ä½¿ç”¨ä¸¥æ ¼åŒ¹é…æ¨¡å¼
    """

    def __init__(
        self,
        dataset: Optional[GAIADataset] = None,
        level: Optional[int] = None,
        local_data_dir: Optional[str] = None,
        strict_mode: bool = True
    ):
        """åˆå§‹åŒ– GAIA è¯„ä¼°å™¨

        Args:
            dataset: GAIA æ•°æ®é›†,å¦‚æœä¸º None åˆ™è‡ªåŠ¨åˆ›å»º
            level: éš¾åº¦çº§åˆ« (1-3)
            local_data_dir: æœ¬åœ°æ•°æ®ç›®å½•
            strict_mode: æ˜¯å¦ä½¿ç”¨ä¸¥æ ¼åŒ¹é…æ¨¡å¼
        """
        self.dataset = dataset or GAIADataset(
            level=level,
            local_data_dir=local_data_dir
        )
        self.metrics = GAIAMetrics()
        self.level = level
        self.strict_mode = strict_mode
        
    def evaluate(self, agent: Any, max_samples: Optional[int] = None) -> Dict[str, Any]:
        """è¯„ä¼°æ™ºèƒ½ä½“

        Args:
            agent: è¦è¯„ä¼°çš„æ™ºèƒ½ä½“
            max_samples: æœ€å¤§è¯„ä¼°æ ·æœ¬æ•°,Noneè¡¨ç¤ºè¯„ä¼°å…¨éƒ¨

        Returns:
            è¯„ä¼°ç»“æœå­—å…¸,åŒ…å«å„é¡¹æŒ‡æ ‡
        """
        print(f"\nğŸŒŸ å¼€å§‹ GAIA è¯„ä¼°...")
        print(f"   æ™ºèƒ½ä½“: {getattr(agent, 'name', 'Unknown')}")
        print(f"   éš¾åº¦çº§åˆ«: {self.level or 'å…¨éƒ¨'}")
        print(f"   åŒ¹é…æ¨¡å¼: {'ä¸¥æ ¼' if self.strict_mode else 'å®½æ¾'}")

        # åŠ è½½æ•°æ®é›†
        dataset = self.dataset.load()
        if not dataset:
            print("   âš ï¸ æ•°æ®é›†ä¸ºç©º,è·³è¿‡è¯„ä¼°")
            return self._create_empty_results(agent)

        # é™åˆ¶æ ·æœ¬æ•°é‡
        if max_samples:
            dataset = dataset[:max_samples]

        print(f"   æ ·æœ¬æ•°é‡: {len(dataset)}")

        # æ‰§è¡Œè¯„ä¼°
        results = []
        level_stats = {1: {"total": 0, "correct": 0, "partial": 0},
                      2: {"total": 0, "correct": 0, "partial": 0},
                      3: {"total": 0, "correct": 0, "partial": 0}}

        for i, sample in enumerate(dataset):
            if i % 10 == 0:
                print(f"   è¿›åº¦: {i+1}/{len(dataset)}")

            try:
                sample_result = self.evaluate_sample(agent, sample)
                results.append(sample_result)

                # æŒ‰çº§åˆ«ç»Ÿè®¡
                level = sample.get("level", 1)
                if level in level_stats:
                    level_stats[level]["total"] += 1
                    if sample_result["exact_match"]:
                        level_stats[level]["correct"] += 1
                    if sample_result["partial_match"]:
                        level_stats[level]["partial"] += 1

            except Exception as e:
                print(f"   âš ï¸ æ ·æœ¬ {i} è¯„ä¼°å¤±è´¥: {e}")
                results.append({
                    "exact_match": False,
                    "partial_match": False,
                    "predicted": None,
                    "expected": sample.get("final_answer"),
                    "error": str(e),
                    "score": 0.0
                })

        # è®¡ç®—æ€»ä½“æŒ‡æ ‡
        total_samples = len(results)
        exact_matches = sum(1 for r in results if r["exact_match"])
        partial_matches = sum(1 for r in results if r["partial_match"])

        exact_match_rate = exact_matches / total_samples if total_samples > 0 else 0.0
        partial_match_rate = partial_matches / total_samples if total_samples > 0 else 0.0

        # è®¡ç®—åˆ†çº§æŒ‡æ ‡
        level_metrics = {}
        for level, stats in level_stats.items():
            if stats["total"] > 0:
                level_metrics[f"Level_{level}"] = {
                    "total": stats["total"],
                    "exact_matches": stats["correct"],
                    "partial_matches": stats["partial"],
                    "exact_match_rate": stats["correct"] / stats["total"],
                    "partial_match_rate": stats["partial"] / stats["total"]
                }

        final_results = {
            "benchmark": "GAIA",
            "agent_name": getattr(agent, 'name', 'Unknown'),
            "strict_mode": self.strict_mode,
            "level_filter": self.level,
            "total_samples": total_samples,
            "exact_matches": exact_matches,
            "partial_matches": partial_matches,
            "exact_match_rate": exact_match_rate,
            "partial_match_rate": partial_match_rate,
            "level_metrics": level_metrics,
            "detailed_results": results
        }

        print(f"âœ… GAIA è¯„ä¼°å®Œæˆ")
        print(f"   ç²¾ç¡®åŒ¹é…ç‡: {exact_match_rate:.2%}")
        print(f"   éƒ¨åˆ†åŒ¹é…ç‡: {partial_match_rate:.2%}")
        for level_name, metrics in level_metrics.items():
            print(f"   {level_name}: {metrics['exact_match_rate']:.2%} ç²¾ç¡® / {metrics['partial_match_rate']:.2%} éƒ¨åˆ†")

        return final_results
    
    def evaluate_sample(self, agent: Any, sample: Dict[str, Any]) -> Dict[str, Any]:
        """è¯„ä¼°å•ä¸ªæ ·æœ¬

        Args:
            agent: è¦è¯„ä¼°çš„æ™ºèƒ½ä½“
            sample: æ ·æœ¬æ•°æ®

        Returns:
            å•ä¸ªæ ·æœ¬çš„è¯„ä¼°ç»“æœ
        """
        try:
            # å‡†å¤‡è¾“å…¥
            question = sample.get("question", "")
            expected_answer = sample.get("final_answer", "")
            level = sample.get("level", 1)
            task_id = sample.get("task_id", "")

            # æ„å»ºæç¤º
            prompt = self._build_prompt(question, sample)

            # è°ƒç”¨æ™ºèƒ½ä½“
            start_time = time.time()
            response = agent.run(prompt)
            execution_time = time.time() - start_time

            # æå–ç­”æ¡ˆ
            predicted_answer = self._extract_answer(response)

            # è¯„ä¼°ç­”æ¡ˆ
            exact_match = self._check_exact_match(predicted_answer, expected_answer)
            partial_match = self._check_partial_match(predicted_answer, expected_answer)

            # è®¡ç®—åˆ†æ•°
            if exact_match:
                score = 1.0
            elif partial_match:
                score = 0.5
            else:
                score = 0.0

            return {
                "task_id": task_id,
                "level": level,
                "exact_match": exact_match,
                "partial_match": partial_match,
                "score": score,
                "predicted": predicted_answer,
                "expected": expected_answer,
                "response": response,
                "execution_time": execution_time
            }

        except Exception as e:
            return {
                "task_id": sample.get("task_id", ""),
                "level": sample.get("level", 1),
                "exact_match": False,
                "partial_match": False,
                "score": 0.0,
                "predicted": None,
                "expected": sample.get("final_answer", ""),
                "error": str(e)
            }

    def _create_empty_results(self, agent: Any) -> Dict[str, Any]:
        """åˆ›å»ºç©ºçš„è¯„ä¼°ç»“æœ"""
        return {
            "benchmark": "GAIA",
            "agent_name": getattr(agent, 'name', 'Unknown'),
            "strict_mode": self.strict_mode,
            "level_filter": self.level,
            "total_samples": 0,
            "exact_matches": 0,
            "partial_matches": 0,
            "exact_match_rate": 0.0,
            "partial_match_rate": 0.0,
            "level_metrics": {},
            "detailed_results": []
        }

    def _build_prompt(self, question: str, sample: Dict[str, Any]) -> str:
        """æ„å»ºè¯„ä¼°æç¤º"""
        # æ„å»ºé—®é¢˜æç¤º
        prompt = f"{question}"

        # å¦‚æœæœ‰æ–‡ä»¶é™„ä»¶ï¼Œæ·»åŠ æç¤º
        if sample.get("file_name"):
            prompt += f"\n\nNote: This question may require reference to the file: {sample['file_name']}"

        return prompt

    def _extract_answer(self, response: str) -> str:
        """ä»å“åº”ä¸­æå–ç­”æ¡ˆï¼ˆGAIAæ ¼å¼ï¼‰

        GAIAè¦æ±‚ç­”æ¡ˆæ ¼å¼ä¸ºï¼šFINAL ANSWER: [ç­”æ¡ˆ]
        """
        # é¦–å…ˆå°è¯•æå–GAIAå®˜æ–¹æ ¼å¼çš„ç­”æ¡ˆ
        final_answer_pattern = r'FINAL ANSWER:\s*(.+?)(?:\n|$)'
        match = re.search(final_answer_pattern, response, re.IGNORECASE | re.MULTILINE)
        if match:
            answer = match.group(1).strip()
            # ç§»é™¤å¯èƒ½çš„æ–¹æ‹¬å·
            answer = answer.strip('[]')
            return answer

        # å¤‡ç”¨æ–¹æ¡ˆï¼šæŸ¥æ‰¾å…¶ä»–ç­”æ¡ˆæ ‡è®°
        answer_patterns = [
            r'ç­”æ¡ˆ[ï¼š:]\s*(.+)',
            r'æœ€ç»ˆç­”æ¡ˆ[ï¼š:]\s*(.+)',
            r'Final answer[ï¼š:]\s*(.+)',
            r'Answer[ï¼š:]\s*(.+)',
        ]

        for pattern in answer_patterns:
            match = re.search(pattern, response, re.IGNORECASE)
            if match:
                return match.group(1).strip()

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡è®°ï¼Œè¿”å›æœ€åä¸€ä¸ªéç©ºè¡Œ
        lines = response.strip().split('\n')
        for line in reversed(lines):
            line = line.strip()
            if line and not line.startswith('#'):
                return line

        return response.strip()

    def _check_exact_match(self, predicted: str, expected: str) -> bool:
        """æ£€æŸ¥ç²¾ç¡®åŒ¹é…"""
        if not predicted or not expected:
            return False

        # æ ‡å‡†åŒ–å­—ç¬¦ä¸²
        pred_normalized = self._normalize_answer(predicted)
        exp_normalized = self._normalize_answer(expected)

        return pred_normalized == exp_normalized

    def _check_partial_match(self, predicted: str, expected: str) -> bool:
        """æ£€æŸ¥éƒ¨åˆ†åŒ¹é…"""
        if not predicted or not expected:
            return False

        # æ ‡å‡†åŒ–å­—ç¬¦ä¸²
        pred_normalized = self._normalize_answer(predicted)
        exp_normalized = self._normalize_answer(expected)

        # æ£€æŸ¥åŒ…å«å…³ç³»
        if exp_normalized in pred_normalized or pred_normalized in exp_normalized:
            return True

        # æ£€æŸ¥å…³é”®è¯åŒ¹é…
        pred_words = set(pred_normalized.split())
        exp_words = set(exp_normalized.split())

        if not exp_words:
            return False

        # å¦‚æœè¶…è¿‡70%çš„æœŸæœ›è¯æ±‡å‡ºç°åœ¨é¢„æµ‹ä¸­ï¼Œè®¤ä¸ºéƒ¨åˆ†åŒ¹é…
        overlap = len(pred_words & exp_words)
        return overlap / len(exp_words) >= 0.7

    def _normalize_answer(self, answer: str) -> str:
        """æ ‡å‡†åŒ–ç­”æ¡ˆå­—ç¬¦ä¸²ï¼ˆGAIAå®˜æ–¹æ ‡å‡†åŒ–è§„åˆ™ï¼‰

        æ ¹æ®GAIAè®ºæ–‡çš„æ ‡å‡†åŒ–è§„åˆ™ï¼š
        1. æ•°å­—ï¼šç§»é™¤é€—å·åˆ†éš”ç¬¦å’Œå•ä½ç¬¦å·
        2. å­—ç¬¦ä¸²ï¼šç§»é™¤å† è¯ã€è½¬å°å†™ã€ç§»é™¤å¤šä½™ç©ºæ ¼
        3. åˆ—è¡¨ï¼šæŒ‰é€—å·åˆ†éš”ï¼Œæ¯ä¸ªå…ƒç´ ç‹¬ç«‹æ ‡å‡†åŒ–
        """
        if not answer:
            return ""

        answer = answer.strip()

        # æ£€æŸ¥æ˜¯å¦æ˜¯é€—å·åˆ†éš”çš„åˆ—è¡¨
        if ',' in answer:
            # åˆ†éš”å¹¶æ ‡å‡†åŒ–æ¯ä¸ªå…ƒç´ 
            parts = [self._normalize_single_answer(p.strip()) for p in answer.split(',')]
            # æŒ‰å­—æ¯é¡ºåºæ’åºï¼ˆGAIAè¦æ±‚ï¼‰
            parts.sort()
            return ','.join(parts)
        else:
            return self._normalize_single_answer(answer)

    def _normalize_single_answer(self, answer: str) -> str:
        """æ ‡å‡†åŒ–å•ä¸ªç­”æ¡ˆï¼ˆä¸åŒ…å«é€—å·çš„ç­”æ¡ˆï¼‰"""
        answer = answer.strip().lower()

        # ç§»é™¤å¸¸è§çš„å† è¯
        articles = ['the', 'a', 'an']
        words = answer.split()
        if words and words[0] in articles:
            words = words[1:]
            answer = ' '.join(words)

        # ç§»é™¤è´§å¸ç¬¦å·å’Œç™¾åˆ†å·
        answer = answer.replace('$', '').replace('%', '').replace('â‚¬', '').replace('Â£', '')

        # ç§»é™¤æ•°å­—ä¸­çš„é€—å·åˆ†éš”ç¬¦ï¼ˆå¦‚ 1,000 -> 1000ï¼‰
        # ä½†ä¿ç•™å°æ•°ç‚¹
        answer = re.sub(r'(\d),(\d)', r'\1\2', answer)

        # ç§»é™¤å¤šä½™ç©ºæ ¼
        answer = ' '.join(answer.split())

        # ç§»é™¤æœ«å°¾çš„æ ‡ç‚¹ç¬¦å·
        answer = answer.rstrip('.,;:!?')

        return answer

    def export_to_gaia_format(
        self,
        results: Dict[str, Any],
        output_path: Union[str, Path],
        include_reasoning: bool = True
    ) -> None:
        """å¯¼å‡ºä¸ºGAIAå®˜æ–¹æ ¼å¼

        GAIAæ ¼å¼è¦æ±‚ï¼š
        - JSONLæ ¼å¼ï¼ˆæ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡ï¼‰
        - æ¯ä¸ªå¯¹è±¡åŒ…å«ï¼štask_id, model_answer, reasoning_traceï¼ˆå¯é€‰ï¼‰

        Args:
            results: è¯„ä¼°ç»“æœ
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            include_reasoning: æ˜¯å¦åŒ…å«æ¨ç†è½¨è¿¹
        """
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        detailed_results = results.get("detailed_results", [])

        with open(output_path, 'w', encoding='utf-8') as f:
            for result in detailed_results:
                gaia_result = {
                    "task_id": result.get("task_id", ""),
                    "model_answer": result.get("predicted", "")
                }

                if include_reasoning:
                    gaia_result["reasoning_trace"] = result.get("response", "")

                f.write(json.dumps(gaia_result, ensure_ascii=False) + '\n')

        print(f"âœ… GAIAæ ¼å¼ç»“æœå·²å¯¼å‡º")
        print(f"   è¾“å‡ºæ–‡ä»¶: {output_path}")
        print(f"   æ ·æœ¬æ•°: {len(detailed_results)}")
        print(f"   åŒ…å«æ¨ç†è½¨è¿¹: {include_reasoning}")

