"""RLè®­ç»ƒå·¥å…·å‡½æ•°"""

import os
from typing import Optional, Dict, Any
from dataclasses import dataclass, field
from pathlib import Path


@dataclass
class TrainingConfig:
    """è®­ç»ƒé…ç½®ç±»"""

    # æ¨¡å‹é…ç½®
    model_name: str = "Qwen/Qwen3-0.6B"
    model_revision: Optional[str] = None
    
    # è®­ç»ƒé…ç½®
    output_dir: str = "./output"
    num_train_epochs: int = 3
    per_device_train_batch_size: int = 4
    gradient_accumulation_steps: int = 4
    learning_rate: float = 5e-5
    warmup_steps: int = 100
    logging_steps: int = 10
    save_steps: int = 500
    eval_steps: int = 500
    
    # RLç‰¹å®šé…ç½®
    max_new_tokens: int = 512
    temperature: float = 0.7
    top_p: float = 0.9
    
    # ç¡¬ä»¶é…ç½®
    use_fp16: bool = True
    use_bf16: bool = False
    gradient_checkpointing: bool = True
    
    # LoRAé…ç½®
    use_lora: bool = True
    lora_r: int = 16
    lora_alpha: int = 32
    lora_dropout: float = 0.05
    lora_target_modules: list = field(default_factory=lambda: ["q_proj", "v_proj"])
    
    # ç›‘æ§é…ç½®
    use_wandb: bool = False
    wandb_project: Optional[str] = None
    use_tensorboard: bool = True
    
    # å…¶ä»–é…ç½®
    seed: int = 42
    max_length: int = 2048
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            k: v for k, v in self.__dict__.items()
            if not k.startswith('_')
        }


def setup_training_environment(config: TrainingConfig) -> None:
    """
    è®¾ç½®è®­ç»ƒç¯å¢ƒ
    
    Args:
        config: è®­ç»ƒé…ç½®
    """
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(config.output_dir, exist_ok=True)
    
    # è®¾ç½®éšæœºç§å­
    import random
    import numpy as np
    try:
        import torch
        torch.manual_seed(config.seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed_all(config.seed)
    except ImportError:
        pass
    
    random.seed(config.seed)
    np.random.seed(config.seed)
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ["TOKENIZERS_PARALLELISM"] = "false"

    # è®¾ç½®wandbé…ç½®
    if config.use_wandb:
        if config.wandb_project:
            os.environ["WANDB_PROJECT"] = config.wandb_project
        os.environ["WANDB_LOG_MODEL"] = "false"  # ä¸ä¸Šä¼ æ¨¡å‹æ–‡ä»¶

    print(f"âœ… è®­ç»ƒç¯å¢ƒè®¾ç½®å®Œæˆ")
    print(f"   - è¾“å‡ºç›®å½•: {config.output_dir}")
    print(f"   - éšæœºç§å­: {config.seed}")
    print(f"   - æ¨¡å‹: {config.model_name}")


def check_trl_installation() -> bool:
    """
    æ£€æŸ¥TRLæ˜¯å¦å·²å®‰è£…
    
    Returns:
        æ˜¯å¦å·²å®‰è£…TRL
    """
    try:
        import trl
        return True
    except ImportError:
        return False


def get_installation_guide() -> str:
    """
    è·å–TRLå®‰è£…æŒ‡å—
    
    Returns:
        å®‰è£…æŒ‡å—æ–‡æœ¬
    """
    return """
TRL (Transformer Reinforcement Learning) æœªå®‰è£…ã€‚

è¯·ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£…ï¼š

æ–¹å¼1ï¼šå®‰è£…HelloAgentsçš„RLåŠŸèƒ½ï¼ˆæ¨èï¼‰
    pip install hello-agents[rl]

æ–¹å¼2ï¼šå•ç‹¬å®‰è£…TRL
    pip install trl

æ–¹å¼3ï¼šä»æºç å®‰è£…æœ€æ–°ç‰ˆæœ¬
    pip install git+https://github.com/huggingface/trl.git

å®‰è£…å®Œæˆåï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹åŠŸèƒ½ï¼š
- SFTè®­ç»ƒï¼ˆç›‘ç£å¾®è°ƒï¼‰
- GRPOè®­ç»ƒï¼ˆç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼‰
- PPOè®­ç»ƒï¼ˆè¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼‰
- DPOè®­ç»ƒï¼ˆç›´æ¥åå¥½ä¼˜åŒ–ï¼‰
- Reward Modelè®­ç»ƒ

æ›´å¤šä¿¡æ¯è¯·è®¿é—®ï¼šhttps://huggingface.co/docs/trl
"""


def format_training_time(seconds: float) -> str:
    """
    æ ¼å¼åŒ–è®­ç»ƒæ—¶é—´
    
    Args:
        seconds: ç§’æ•°
        
    Returns:
        æ ¼å¼åŒ–çš„æ—¶é—´å­—ç¬¦ä¸²
    """
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    
    if hours > 0:
        return f"{hours}h {minutes}m {secs}s"
    elif minutes > 0:
        return f"{minutes}m {secs}s"
    else:
        return f"{secs}s"


def get_device_info() -> Dict[str, Any]:
    """
    è·å–è®¾å¤‡ä¿¡æ¯
    
    Returns:
        è®¾å¤‡ä¿¡æ¯å­—å…¸
    """
    info = {
        "cuda_available": False,
        "cuda_device_count": 0,
        "cuda_device_name": None,
    }
    
    try:
        import torch
        info["cuda_available"] = torch.cuda.is_available()
        if info["cuda_available"]:
            info["cuda_device_count"] = torch.cuda.device_count()
            info["cuda_device_name"] = torch.cuda.get_device_name(0)
    except ImportError:
        pass
    
    return info


def print_training_summary(
    algorithm: str,
    model_name: str,
    dataset_name: str,
    num_epochs: int,
    output_dir: str
) -> None:
    """
    æ‰“å°è®­ç»ƒæ‘˜è¦
    
    Args:
        algorithm: ç®—æ³•åç§°
        model_name: æ¨¡å‹åç§°
        dataset_name: æ•°æ®é›†åç§°
        num_epochs: è®­ç»ƒè½®æ•°
        output_dir: è¾“å‡ºç›®å½•
    """
    device_info = get_device_info()
    
    print("\n" + "="*60)
    print(f"ğŸš€ å¼€å§‹ {algorithm} è®­ç»ƒ")
    print("="*60)
    print(f"ğŸ“¦ æ¨¡å‹: {model_name}")
    print(f"ğŸ“Š æ•°æ®é›†: {dataset_name}")
    print(f"ğŸ”„ è®­ç»ƒè½®æ•°: {num_epochs}")
    print(f"ğŸ’¾ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"ğŸ–¥ï¸  è®¾å¤‡: {'GPU' if device_info['cuda_available'] else 'CPU'}")
    if device_info['cuda_available']:
        print(f"   - GPUæ•°é‡: {device_info['cuda_device_count']}")
        print(f"   - GPUå‹å·: {device_info['cuda_device_name']}")
    print("="*60 + "\n")

